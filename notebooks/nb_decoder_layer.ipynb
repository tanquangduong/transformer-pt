{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d0314e-26ba-4148-875d-12271af89f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from transformer.layers import MultiHeadAttention, FeedForward, ResidualConnection\n",
    "from transformer.decoder import DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f647f4-cd79-4cf9-b8d4-9758dfb3dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions, number of heads, dropout rate, and number of layers\n",
    "d_model = 512\n",
    "h = 8\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the MultiHeadAttention and FeedForward classes\n",
    "self_attention = MultiHeadAttention(d_model, h, dropout)\n",
    "encoder_decoder_attention = MultiHeadAttention(d_model, h, dropout)\n",
    "feed_forward = FeedForward(d_model, 2048, dropout)  # 2048 is the dimension of the feed forward network\n",
    "\n",
    "# Create an instance of the DecoderLayer class\n",
    "decoder_layer = DecoderLayer(d_model, self_attention, encoder_decoder_attention, feed_forward, dropout)\n",
    "\n",
    "# Create a random tensor to represent a batch of sequences\n",
    "x = torch.rand(10, 20, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "encoder_output = torch.rand(10, 20, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "\n",
    "# Pass the tensor through the decoder layer\n",
    "output = decoder_layer(x, encoder_output)\n",
    "\n",
    "print(output.shape)  # Should print: torch.Size([10, 20, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ecb1ad-a37d-41ad-9466-b4d41d2a5f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9451,  0.0460,  0.5849,  ...,  0.2033,  0.8243,  0.6452],\n",
       "         [ 1.2801,  0.1327,  0.6657,  ...,  0.4800,  0.6743,  1.0419],\n",
       "         [ 1.0468,  0.9214,  1.1230,  ...,  0.4176,  0.1183,  0.7932],\n",
       "         ...,\n",
       "         [ 0.3962,  0.0462,  0.9414,  ...,  1.1050,  0.8406,  0.5332],\n",
       "         [ 0.9542,  0.7625,  0.1488,  ...,  0.1194,  0.5439,  0.5755],\n",
       "         [ 0.5434,  0.5958,  1.1628,  ...,  0.2215,  0.4805,  0.4943]],\n",
       "\n",
       "        [[ 0.7126,  0.7812,  0.0621,  ...,  0.0663,  0.4471,  0.1950],\n",
       "         [ 0.9117,  0.6038,  0.5533,  ...,  0.4439,  0.5727,  0.8861],\n",
       "         [ 0.7663,  0.0433,  0.5142,  ...,  0.5397,  0.7266,  1.4013],\n",
       "         ...,\n",
       "         [ 0.4492,  0.9554,  0.2706,  ...,  0.4006,  0.1882,  0.8003],\n",
       "         [ 0.6554,  1.1181,  0.2980,  ...,  0.9070,  0.3214,  1.1477],\n",
       "         [ 0.6537,  0.4406,  1.2279,  ...,  1.0520,  0.9557,  1.3224]],\n",
       "\n",
       "        [[ 1.5008,  0.6873,  1.1075,  ...,  0.4526,  0.1823,  0.4263],\n",
       "         [ 0.7362, -0.4344,  0.9022,  ...,  0.9795,  0.2755,  0.4932],\n",
       "         [ 1.1357,  0.8219,  0.1861,  ...,  0.5900,  0.0109,  1.0108],\n",
       "         ...,\n",
       "         [ 0.5786,  0.9989,  0.1278,  ...,  0.5623, -0.0753,  0.8044],\n",
       "         [ 0.5666,  0.4916,  0.3484,  ..., -0.0456,  0.4676,  0.6709],\n",
       "         [ 1.0769,  1.0927,  0.6704,  ...,  0.1794,  0.1216,  0.8912]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9101,  0.2112,  0.8136,  ...,  0.8453,  1.4462,  0.2531],\n",
       "         [ 0.5840,  0.8681,  1.1880,  ...,  0.2298,  1.0071,  1.3118],\n",
       "         [ 0.5479,  0.3938,  1.3491,  ...,  1.0754,  0.2539,  0.8574],\n",
       "         ...,\n",
       "         [ 0.5895, -0.0750,  0.4440,  ...,  0.8356,  0.6197,  0.7673],\n",
       "         [ 0.2085,  0.6925,  0.0957,  ..., -0.0847,  0.6011,  0.9812],\n",
       "         [-0.1833,  0.4267,  0.6930,  ...,  0.7692,  0.3726,  0.4279]],\n",
       "\n",
       "        [[ 0.8855,  0.9487,  0.2913,  ...,  0.8952,  0.4132,  0.6378],\n",
       "         [ 0.7351,  0.6652,  0.5062,  ...,  0.7375,  0.3100,  0.1782],\n",
       "         [ 1.3709,  0.8505,  1.1573,  ...,  0.3884,  1.3102,  0.7583],\n",
       "         ...,\n",
       "         [ 0.6954,  0.5963,  0.5863,  ...,  0.3954,  0.0785,  0.9671],\n",
       "         [ 0.4996,  1.2127,  0.1534,  ...,  0.3029,  0.1184,  0.2303],\n",
       "         [ 0.9706,  0.4134,  0.8822,  ...,  0.5917,  0.5944,  0.8988]],\n",
       "\n",
       "        [[ 0.8859,  0.6843,  1.3831,  ...,  0.3900, -0.1822, -0.0118],\n",
       "         [ 1.2583,  0.6469,  0.9611,  ...,  0.8494,  0.2017,  0.4914],\n",
       "         [ 0.8713,  0.9101,  0.4627,  ...,  0.6635,  0.4705,  0.0838],\n",
       "         ...,\n",
       "         [ 1.3437, -0.0222,  1.0263,  ..., -0.0698,  0.1780,  1.1723],\n",
       "         [ 0.5049,  1.1837,  0.5136,  ..., -0.2034,  0.9030,  1.0657],\n",
       "         [ 0.2115,  0.3086,  0.8449,  ...,  0.4457,  0.6405,  1.1535]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9f5e9-86ce-4c76-9acb-02be240435ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
