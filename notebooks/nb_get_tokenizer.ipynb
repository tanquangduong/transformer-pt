{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0302a682-477d-4a12-b6c2-128594b0f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from transformer.utils import load_config, get_dataset, get_tokenizer, timer, calculate_max_lengths\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac2195-1c9c-4503-af0e-8679088016f8",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5223de-df06-4938-bd2f-3f3052bba9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"../config.json\"\n",
    "config = load_config(config_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93d757-29d7-41ca-a103-16a5b118977e",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b28f07d-cabb-4de7-93eb-2f4a57ab2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c2dbc6-0540-4796-b147-fe41077f428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'translation'],\n",
       "    num_rows: 209479\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b052d1eb-166c-4d0d-a39c-23be626f9e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'en': '$10,000 Gold?', 'fr': 'L’or à 10.000 dollars l’once\\xa0?'},\n",
       " {'en': 'SAN FRANCISCO – It has never been easy to have a rational conversation about the value of gold.',\n",
       "  'fr': 'SAN FRANCISCO – Il n’a jamais été facile d’avoir une discussion rationnelle sur la valeur du métal jaune.'},\n",
       " {'en': 'Lately, with gold prices up more than 300% over the last decade, it is harder than ever.',\n",
       "  'fr': 'Et aujourd’hui, alors que le cours de l’or a augmenté de 300 pour cent au cours de la dernière décennie, c’est plus difficile que jamais.'},\n",
       " {'en': 'Just last December, fellow economists Martin Feldstein and Nouriel Roubini each penned op-eds bravely questioning bullish market sentiment, sensibly pointing out gold’s risks.',\n",
       "  'fr': 'En décembre dernier, mes collègues économistes Martin Feldstein et Nouriel Roubini ont chacun publié une tribune libre dans laquelle ils doutaient courageusement du marché haussier, soulignant de manière sensée les risques liés à l’or.'},\n",
       " {'en': 'Wouldn’t you know it?', 'fr': 'Mais devinez ce qui s’est passé\\xa0?'},\n",
       " {'en': 'Since their articles appeared, the price of gold has moved up still further. Gold prices even hit a record-high $1,300 recently.',\n",
       "  'fr': 'Depuis la parution de leurs articles, le cours de l’or a encore grimpé, pour atteindre récemment un plus haut historique de 1300 dollars l’once.'},\n",
       " {'en': 'Last December, many gold bugs were arguing that the price was inevitably headed for $2,000.',\n",
       "  'fr': 'En décembre dernier, plusieurs investisseurs dans le métal jaune estimaient que l’once atteindrait inévitablement les 2000 dollars.'},\n",
       " {'en': 'Now, emboldened by continuing appreciation, some are suggesting that gold could be headed even higher than that.',\n",
       "  'fr': 'Aujourd’hui, encouragés par son appréciation constante, certains suggèrent qu’il pourrait grimper encore.'},\n",
       " {'en': 'One successful gold investor recently explained to me that stock prices languished for a more than a decade before the Dow Jones index crossed the 1,000 mark in the early 1980’s.',\n",
       "  'fr': 'Un particulier qui a investi avec succès dans le métal précieux m’a récemment expliqué que les cours de la Bourse avaient stagné pendant une décennie avant que l’indice Dow Jones passe la barre des 1000 points.'},\n",
       " {'en': 'Since then, the index has climbed above 10,000.',\n",
       "  'fr': 'Depuis lors, le Dow Jones a dépassé la barre des 10.000 points.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['translation'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42875e9-628a-4e14-bc31-45b3dbbc3618",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82bc0cb-63c0-4e9b-92f2-1697880ac7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_src = get_tokenizer(config, dataset, config['language_source'])\n",
    "\n",
    "tokenizer_tgt = get_tokenizer(config, dataset, config['language_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430d9e3-3c57-49b0-a7b0-e4d1769cc204",
   "metadata": {},
   "source": [
    "## Explore tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49477a04-7b6d-4b0a-a711-a3fbfec9cbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocabulary size:  30000\n",
      "Target vocabulary size:  30000\n"
     ]
    }
   ],
   "source": [
    "# check vocabulary size\n",
    "print(\"Source vocabulary size: \", tokenizer_src.get_vocab_size())\n",
    "print(\"Target vocabulary size: \", tokenizer_tgt.get_vocab_size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab46f42-31bd-4f15-b44d-188bbb8f5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tokenizer encodes 'I love you':  [131, 3181, 345]\n",
      "Source tokenizer decodes [131, 3181, 345]:  I love you\n"
     ]
    }
   ],
   "source": [
    "# Check source tokenizer encodes/decodes\n",
    "print(\"Source tokenizer encodes 'I love you': \", tokenizer_src.encode('I love you').ids)\n",
    "print(\"Source tokenizer decodes [131, 3181, 345]: \", tokenizer_src.decode([131, 3181, 345])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c98f48-3550-4aea-b6be-42b6c5d527cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target tokenizer encodes 'Je vais bien':  [783, 11957, 70]\n",
      "Target tokenizer decodes [783, 11957, 70]:  Je vais bien\n"
     ]
    }
   ],
   "source": [
    "# Check source tokenizer encodes/decodes\n",
    "print(\"Target tokenizer encodes 'Je vais bien': \", tokenizer_tgt.encode('Je vais bien' ).ids)\n",
    "print(\"Target tokenizer decodes [783, 11957, 70]: \", tokenizer_tgt.decode([783, 11957, 70])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0597c4fd-135a-4602-8927-afb3f6d3f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tokenizer encodes'Love': [17854]\n",
      "Source tokenizer encodes 'love':  [3181]\n"
     ]
    }
   ],
   "source": [
    "# Comparing Uppercase anc Lowercase words\n",
    "print(\"Source tokenizer encodes'Love':\", tokenizer_src.encode('Love').ids)\n",
    "print(\"Source tokenizer encodes 'love': \", tokenizer_src.encode('love').ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550de2d4-f4cf-44cd-b305-472738b27485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tokenizer encodes'Love':  17854\n",
      "Source tokenizer encodes'love':  3181\n"
     ]
    }
   ],
   "source": [
    "# check token_to_id method\n",
    "print(\"Source tokenizer encodes'Love': \", tokenizer_src.token_to_id('Love'))\n",
    "print(\"Source tokenizer encodes'love': \", tokenizer_src.token_to_id('love'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a3aa8f-43a0-4c6f-b41f-4758940a0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tokenizer decodes 17854: Love\n",
      "Source tokenizer decodes 3181: love\n"
     ]
    }
   ],
   "source": [
    "# check id_to_token method\n",
    "print(\"Source tokenizer decodes 17854:\", tokenizer_src.id_to_token(17854))\n",
    "print(\"Source tokenizer decodes 3181:\", tokenizer_src.id_to_token(3181))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a6d19-2938-4483-af20-4467ca98dc35",
   "metadata": {},
   "source": [
    "## Check maximum length of source and target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8303978-4101-41bc-bf83-ed910d280e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 50.593788385391235 seconds\n",
      "Maximum length of source sentences:  222\n",
      "Maximum length of target sentences:  348\n"
     ]
    }
   ],
   "source": [
    "# Use the function\n",
    "max_src_len, max_tgt_len = calculate_max_lengths(dataset, tokenizer_src, tokenizer_tgt, config)\n",
    "print(\"Maximum length of source sentences: \", max_src_len)\n",
    "print(\"Maximum length of target sentences: \", max_tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a738c779-1c97-490e-a89b-4d46ca43d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.token_to_id('[SOS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8dbe168-2d7d-4b41-8cc2-abfb1a3ea0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.token_to_id('[EOS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cc6ec-9aca-456a-a954-3c14e535c720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
