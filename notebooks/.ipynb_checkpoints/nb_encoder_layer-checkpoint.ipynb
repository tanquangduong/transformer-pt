{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82056c0e-6cf0-4277-aa01-82271513cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.layers import FeedForward, MultiHeadAttention, ResidualConnection\n",
    "from transformer.encoder import EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36454aac-8ffc-4cae-a6ee-f102396022c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions, number of heads, and dropout rate\n",
    "d_model = 512\n",
    "h = 8\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the MultiHeadAttention and FeedForward classes\n",
    "self_attention_engine = MultiHeadAttention(d_model, h, dropout)\n",
    "feed_forward = FeedForward(d_model, 2048, dropout)  # 2048 is the dimension of the feed forward network\n",
    "\n",
    "# Create an instance of the EncoderLayer class\n",
    "encoder_layer = EncoderLayer(d_model, self_attention_engine, feed_forward, dropout)\n",
    "\n",
    "# Create a random tensor to represent a batch of sequences\n",
    "x = torch.rand(10, 20, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "\n",
    "# Pass the tensor through the encoder layer\n",
    "output = encoder_layer(x)\n",
    "\n",
    "print(output.shape)  # Should print: torch.Size([10, 20, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9fcedf-4cfe-4676-a1ff-a9d0340215a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3765,  1.3133,  0.4296,  ...,  0.3447,  0.5974,  0.5979],\n",
       "         [ 1.4624, -0.2803,  0.7468,  ...,  0.3159,  0.2472,  1.0417],\n",
       "         [ 0.4748,  1.2237,  0.4470,  ...,  0.2309,  0.8653,  1.2811],\n",
       "         ...,\n",
       "         [ 0.7394,  0.1945, -0.1160,  ...,  0.7885,  0.4199,  0.9771],\n",
       "         [ 0.9399,  1.3293,  0.2176,  ...,  0.2676,  0.5518,  0.5426],\n",
       "         [ 0.2271,  0.7219,  0.4958,  ...,  0.5735,  0.3270,  0.4344]],\n",
       "\n",
       "        [[ 1.5036,  0.5801,  0.6832,  ...,  0.2888,  0.6860,  0.8315],\n",
       "         [ 0.9217,  0.6100,  0.6812,  ...,  0.6223, -0.0917,  0.2168],\n",
       "         [ 0.4333,  0.0018,  0.3359,  ...,  0.5424,  0.1439,  1.1066],\n",
       "         ...,\n",
       "         [ 1.2167,  0.0935,  0.3862,  ...,  0.2283,  1.0166,  0.6631],\n",
       "         [ 0.6969, -0.1154,  0.4839,  ...,  0.4715,  1.1560,  1.1501],\n",
       "         [ 0.5669,  0.3980,  0.3362,  ...,  0.8104,  0.4619,  0.3955]],\n",
       "\n",
       "        [[ 0.9560,  0.6041,  0.6384,  ...,  0.3795,  0.8063,  0.3157],\n",
       "         [-0.1868, -0.0701,  0.7431,  ...,  0.3587,  0.3815,  0.3375],\n",
       "         [ 0.4529,  0.9528,  0.9157,  ...,  0.1498,  0.3166,  0.4463],\n",
       "         ...,\n",
       "         [ 1.0613,  0.2230,  0.4559,  ...,  0.8456,  0.2982,  1.0854],\n",
       "         [ 0.4132,  0.3257,  0.5086,  ...,  0.5237,  0.3676,  1.2371],\n",
       "         [ 1.1401,  0.0121,  0.9780,  ...,  0.3835,  0.8545,  0.6436]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0460, -0.0791,  1.1236,  ...,  0.6314,  0.3860,  0.6251],\n",
       "         [ 1.2365,  1.1359,  0.6036,  ...,  0.3103,  0.4158,  0.8620],\n",
       "         [ 0.6193,  0.1717,  0.4431,  ...,  0.5103,  0.0685,  1.2745],\n",
       "         ...,\n",
       "         [ 0.7571,  0.7827,  0.7588,  ...,  0.4891, -0.0115,  0.6863],\n",
       "         [ 0.7943,  0.6110,  0.8156,  ...,  0.2970,  0.4254,  0.3106],\n",
       "         [ 0.9426,  0.4282,  0.5319,  ...,  0.6787,  0.6726,  0.5661]],\n",
       "\n",
       "        [[ 1.2135,  0.1193, -0.2025,  ...,  0.0885, -0.0344,  0.6266],\n",
       "         [ 0.9342,  0.2225,  0.1193,  ...,  0.1171,  0.5041,  0.3459],\n",
       "         [ 1.3718,  0.6958,  0.4111,  ...,  0.0912,  0.5715,  0.5131],\n",
       "         ...,\n",
       "         [ 0.6613,  0.3894,  0.8830,  ..., -0.0069,  0.4021,  1.1534],\n",
       "         [ 0.8626,  1.0777, -0.2721,  ...,  0.4595,  0.7559,  0.6737],\n",
       "         [ 1.4360,  1.0125,  0.4016,  ...,  0.7279,  0.1623,  0.9707]],\n",
       "\n",
       "        [[ 0.8326,  0.4754,  0.7316,  ...,  0.2322,  0.0809,  0.6403],\n",
       "         [ 0.9615, -0.1384,  0.4802,  ...,  0.1025,  0.9607,  1.2420],\n",
       "         [ 0.0500,  0.8961,  0.2707,  ...,  0.1377, -0.0016,  1.3675],\n",
       "         ...,\n",
       "         [ 0.6084,  0.2726, -0.1708,  ...,  0.9271,  0.6426,  1.1622],\n",
       "         [ 0.6334,  0.0441,  0.3344,  ...,  0.3693,  0.0590,  0.7702],\n",
       "         [ 0.2367,  1.5198, -0.3504,  ...,  0.0136,  0.3755,  0.7688]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f6f6e-af12-4a0c-a0dd-6372c568cb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
