{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c498edb-bc22-4890-89c0-eb5797b1c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_ids: tensor([ 2, 68, 72,  3,  0])\n",
      "encoder_input_ids shape: torch.Size([5])\n",
      "\n",
      "\n",
      "encoder_mask: tensor([[[1, 1, 1, 1, 0]]], dtype=torch.int32)\n",
      "encoder_mask shape: torch.Size([1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from transformer.mask import create_encoder_mask\n",
    "# Initiate encoder_input_ids and pad_token_id\n",
    "encoder_input_ids = torch.tensor([ 2, 68, 72, 3, 0])\n",
    "pad_token_id = torch.tensor([0])\n",
    "\n",
    "# Create encoder mask\n",
    "encoder_mask = create_encoder_mask(encoder_input_ids, pad_token_id)\n",
    "\n",
    "print(\"encoder_input_ids:\", encoder_input_ids)\n",
    "print(\"encoder_input_ids shape:\", encoder_input_ids.shape)\n",
    "print(\"\\n\")\n",
    "print(\"encoder_mask:\", encoder_mask)\n",
    "print(\"encoder_mask shape:\", encoder_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d62b1c5-5759-4e93-9280-c56469bae164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_input_ids: tensor([ 2, 68, 72, 96,  0])\n",
      "decoder_input_ids shape: torch.Size([5])\n",
      "\n",
      "\n",
      "padding_mask: \n",
      " tensor([[1, 1, 1, 1, 0]], dtype=torch.int32)\n",
      "padding_mask shape: torch.Size([1, 5])\n",
      "\n",
      "\n",
      "causal_mask: \n",
      " tensor([[[ True, False, False, False, False],\n",
      "         [ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True]]])\n",
      "causal_mask shape: torch.Size([1, 5, 5])\n",
      "\n",
      "\n",
      "decoder_mask: \n",
      " tensor([[[1, 0, 0, 0, 0],\n",
      "         [1, 1, 0, 0, 0],\n",
      "         [1, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 1, 0]]], dtype=torch.int32)\n",
      "decoder_mask shape: torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from transformer.mask import create_padding_mask, create_causal_mask, create_decoder_mask\n",
    "\n",
    "# Create the inputs \n",
    "decoder_input_ids = torch.tensor([ 2, 68, 72, 96, 0])\n",
    "pad_token_id = torch.tensor([0]) # padding token ID\n",
    "seq_len = 5 # sequence length\n",
    "\n",
    "\n",
    "print(\"decoder_input_ids:\", decoder_input_ids)\n",
    "print(\"decoder_input_ids shape:\", decoder_input_ids.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create padding mask\n",
    "padding_mask = create_padding_mask(decoder_input_ids, pad_token_id) # (1, seq_len)\n",
    "print(\"padding_mask: \\n\", padding_mask)\n",
    "print(\"padding_mask shape:\", padding_mask.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create a causal mask \n",
    "causal_mask = create_causal_mask(seq_len)\n",
    "print('causal_mask: \\n', causal_mask)\n",
    "print('causal_mask shape:', causal_mask.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create decoder mask\n",
    "decoder_mask = create_decoder_mask(decoder_input_ids, pad_token_id, seq_len)\n",
    "print('decoder_mask: \\n', decoder_mask)\n",
    "print('decoder_mask shape:', decoder_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96f524ec-002a-4039-af5b-f14f0ab842df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from transformer.mask import *\n",
    "\n",
    "# Create the inputs \n",
    "en_input_ids = torch.tensor([ 2, 68, 72, 3, 0])\n",
    "de_input_ids = torch.tensor([ 2, 68, 72, 96, 0])\n",
    "pad_id = torch.tensor([0]) # pad token id\n",
    "seq_len = 5 # sequence length\n",
    "\n",
    "# Create encoder mask\n",
    "encoder_mask = create_encoder_mask(en_input_ids, pad_id) \n",
    "# (1, 1, seq_len)\n",
    "\n",
    "# Create padding mask\n",
    "padding_mask = create_padding_mask(de_input_ids, pad_id) \n",
    "# (1, seq_len)\n",
    "\n",
    "# Create a causal mask \n",
    "causal_mask = create_causal_mask(seq_len)\n",
    "# (1, seq_len, seq_len)\n",
    "\n",
    "# Create decoder mask\n",
    "decoder_mask = create_decoder_mask(de_input_ids, pad_id, seq_len)\n",
    "# (1, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0289f9a-9e6c-48bb-8a4c-14c2b7635f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
