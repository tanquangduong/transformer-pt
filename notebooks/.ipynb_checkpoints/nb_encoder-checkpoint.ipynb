{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433dfc69-c6b6-4852-b020-5f51c93cbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from transformer.layers import MultiHeadAttention, FeedForward, LayerNorm\n",
    "from transformer.encoder import EncoderLayer, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f3d41a-87b7-4aa6-b8b3-162d84477571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the dimensions, number of heads, dropout rate, and number of layers\n",
    "d_model = 512\n",
    "h = 8\n",
    "dropout = 0.1\n",
    "num_layers = 6\n",
    "d_ff = 2048 # the dimension of the feed forward network\n",
    "batch = 10\n",
    "seq_len = 20\n",
    "\n",
    "# Create an instance of the MultiHeadAttention and FeedForward classes\n",
    "self_attention_engine = MultiHeadAttention(d_model, h, dropout)\n",
    "feed_forward = FeedForward(d_model, d_ff, dropout)  \n",
    "\n",
    "# Create an instance of the EncoderLayer class\n",
    "encoder_layer = EncoderLayer(d_model, self_attention_engine, feed_forward, dropout)\n",
    "\n",
    "# Create an instance of the Encoder class\n",
    "encoder = Encoder(d_model, encoder_layer, num_layers)\n",
    "\n",
    "# Create a random tensor to represent a batch of sequences\n",
    "x = torch.rand(batch, seq_len, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "\n",
    "# Pass the tensor through the encoder\n",
    "output = encoder(x)\n",
    "\n",
    "print(output.shape)  # Should print: torch.Size([10, 20, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26db5f0f-5e7c-43c1-afa9-0ae6cd30c650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2745, -1.3341,  1.8563,  ..., -0.7987, -0.4595, -2.0738],\n",
       "         [-2.1539,  0.0743,  1.8552,  ..., -1.3345, -1.8894, -2.2995],\n",
       "         [-1.1547, -0.4120,  1.2284,  ..., -0.3696, -0.2565, -1.4057],\n",
       "         ...,\n",
       "         [-1.6552,  0.1109,  1.2367,  ..., -0.4721, -0.9330, -2.0241],\n",
       "         [-0.8082, -0.1798,  1.3354,  ..., -1.2474, -0.7440, -1.6114],\n",
       "         [-1.1402, -0.5075,  0.2664,  ..., -0.5437, -1.4057, -2.1198]],\n",
       "\n",
       "        [[-1.0775, -0.6065,  0.9312,  ...,  0.3671, -1.0054, -1.7633],\n",
       "         [-1.5911, -0.3359,  1.2845,  ..., -1.0076, -1.4768, -1.8935],\n",
       "         [-1.0480, -0.7467,  1.7230,  ..., -0.6521, -0.8205, -2.0892],\n",
       "         ...,\n",
       "         [-1.3126, -1.3663,  1.4949,  ..., -0.6949, -1.2023, -1.4043],\n",
       "         [-0.3771, -1.2371,  0.7752,  ..., -0.4985, -0.8243, -0.9701],\n",
       "         [-1.1369, -0.0368,  1.4173,  ..., -0.9032, -0.7359, -1.7543]],\n",
       "\n",
       "        [[-0.2336, -1.0617,  1.4119,  ..., -0.2019, -0.5825, -1.0645],\n",
       "         [-0.0915, -1.4929,  1.8660,  ..., -1.1647, -0.7459, -0.7945],\n",
       "         [ 0.1039, -0.6589,  1.2233,  ..., -0.6208, -1.1076, -2.2068],\n",
       "         ...,\n",
       "         [-0.5043, -0.2793,  0.9063,  ..., -1.2715, -0.3045, -1.4763],\n",
       "         [-0.6462, -0.6027,  1.4994,  ..., -1.0657, -0.3141, -1.7739],\n",
       "         [ 0.7196, -0.5475,  0.8621,  ..., -0.6092, -0.4538, -1.8795]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.5925, -0.7771,  0.9664,  ..., -0.6868, -1.2548, -1.5971],\n",
       "         [-1.1969, -0.8685,  1.1411,  ..., -0.5233, -0.8802, -1.3066],\n",
       "         [-0.0742, -0.7687,  1.2797,  ..., -0.7778, -1.0484, -1.3677],\n",
       "         ...,\n",
       "         [-0.6011, -0.8417,  0.9779,  ..., -1.0757, -1.4565, -2.3168],\n",
       "         [-1.6638, -0.8031,  2.4032,  ..., -0.3240, -1.3403, -1.5724],\n",
       "         [-2.0627, -0.9377,  1.9678,  ..., -1.9854, -0.7466, -1.0895]],\n",
       "\n",
       "        [[-1.1886, -1.2070,  3.0007,  ..., -0.5865, -0.1191, -0.3665],\n",
       "         [-0.8793, -0.1344,  1.3729,  ..., -0.5684, -0.9512, -0.3559],\n",
       "         [-0.0518, -0.9616,  1.5142,  ..., -0.3664, -0.6125, -0.8494],\n",
       "         ...,\n",
       "         [-0.7069, -1.6786,  1.9344,  ..., -1.2571, -0.5393, -0.4470],\n",
       "         [-1.8665, -1.2043,  1.7002,  ..., -0.3239, -0.7583, -1.2206],\n",
       "         [-1.4353, -0.6805,  1.8927,  ..., -0.4134, -0.6746, -0.7197]],\n",
       "\n",
       "        [[-0.2556, -2.5712,  1.3575,  ...,  0.0163, -0.0159, -1.3323],\n",
       "         [-2.1461, -0.9966,  1.7201,  ...,  0.1619, -0.1994, -2.3607],\n",
       "         [ 0.5311, -1.1772,  0.2170,  ...,  0.2442,  0.6153, -1.3212],\n",
       "         ...,\n",
       "         [-1.4024, -1.0902,  0.5250,  ..., -0.5466,  0.0648, -2.9393],\n",
       "         [-0.3996, -1.3828,  2.2236,  ...,  0.9133,  0.1684, -1.9836],\n",
       "         [-0.4714, -1.1721,  1.6051,  ...,  0.1441,  0.0826, -1.5288]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b8a80-879b-40c0-b156-bb45c916c2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
