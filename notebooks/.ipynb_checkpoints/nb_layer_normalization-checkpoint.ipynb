{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c40281b-99b9-4322-a5e6-0c5270f29d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1acd574-eec6-44b1-9ff2-b830f005e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, feature_len: int, eps: float=1e-6) -> None: \n",
    "        super().__init__()\n",
    "        self.para_mul = nn.Parameter(torch.ones(feature_len))\n",
    "        self.para_bias = nn.Parameter(torch.zeros(feature_len))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x): # x: [batch_size, seq_len, d_model]\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.para_mul * (x - mean) / (std + self.eps) + self.para_bias # [batch_size, seq_len, d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf60bcd5-697c-469d-986d-b0ccf7833f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 300])\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have a feature length of 300\n",
    "feature_len = 300\n",
    "\n",
    "# Create an instance of our LayerNorm class\n",
    "layer_norm = LayerNorm(feature_len)\n",
    "\n",
    "# Suppose we have the following batch of 2 sequences (mini-batch size of 2)\n",
    "# Each sequence has 4 words (sequence length of 4)\n",
    "# Each word is represented by a 300-dimensional vector (d_model = 300)\n",
    "x = torch.rand(2, 4, 300)\n",
    "\n",
    "# Pass our sequences through the layer normalization\n",
    "normalized_sequences = layer_norm(x)\n",
    "\n",
    "print(normalized_sequences.shape)  # Should output: torch.Size([2, 4, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21957a55-0974-4bef-a2cf-018f445be01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0197, -1.0291,  0.9568,  ..., -0.0539,  0.2884,  0.7148],\n",
       "         [ 0.2491,  1.4138,  1.1152,  ..., -0.5740, -0.6588,  0.0357],\n",
       "         [ 0.3927, -1.2732,  0.9233,  ...,  0.9915,  0.7239,  0.4172],\n",
       "         [ 0.4524, -0.2981, -1.0243,  ..., -0.5243, -1.6016,  0.9814]],\n",
       "\n",
       "        [[-0.6347,  0.9279, -1.0341,  ..., -0.0521, -0.8354, -0.7375],\n",
       "         [-1.5796,  0.8898,  0.2707,  ...,  0.0209, -0.7101,  1.1840],\n",
       "         [-1.7730, -1.0018, -1.7518,  ...,  1.3988, -0.8080, -0.7552],\n",
       "         [ 0.2187, -1.0349, -0.0763,  ...,  1.4860, -1.4960,  0.9116]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255738f-8124-4c59-998d-fc6127088859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
