{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113fed67-4d7c-490e-ab2b-3fb2e6de09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from transformer.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b2a44-87df-4964-a7f7-1c993697b132",
   "metadata": {},
   "source": [
    "## Example to calculate multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce6a1cb-fbc1-4acd-ba45-2584eb19b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions, number of heads, and dropout rate\n",
    "d_model = 512\n",
    "h = 8\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the MultiHeadAttention class\n",
    "multi_head_attention = MultiHeadAttention(d_model, h, dropout)\n",
    "\n",
    "# Create random tensors to represent a batch of sequences for query, key, and value\n",
    "query = torch.rand(10, 20, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "key = torch.rand(10, 20, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "value = torch.rand(10, 20, d_model)  # batch_size=10, seq_len=20, d_model=512\n",
    "\n",
    "# Pass the tensors through the multi-head attention layer\n",
    "output = multi_head_attention(query, key, value)\n",
    "\n",
    "print(output.shape)  # Should print: torch.Size([10, 20, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424b4c6-87ea-484d-bacb-86534182de81",
   "metadata": {},
   "source": [
    "## Example to calculate attention and attention score on single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee85631-3764-43be-acd1-a5899f7934ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 6, 64])\n",
      "torch.Size([1, 8, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "d_k = 64\n",
    "\n",
    "# Create an instance of the MultiHeadAttention class\n",
    "multi_head_attention = MultiHeadAttention(d_model=512, h=8, dropout=0.1)\n",
    "\n",
    "# Create random tensors to represent a batch of sequences for query, key, and value\n",
    "query_k = torch.rand(1, 8, 6, d_k)  # batch_size=1, h=8, seq_len=6, d_k=64\n",
    "key_k = torch.rand(1, 8, 6, d_k)  # batch_size=1, h=8, seq_len=6, d_k=64\n",
    "value_k = torch.rand(1, 8, 6, d_k)  # batch_size=1, h=8, seq_len=6, d_k=64\n",
    "\n",
    "# Pass the tensors through the attention method\n",
    "output, attention_score = MultiHeadAttention.attention(query_k, key_k, value_k, d_k, dropout=nn.Dropout(0.1))\n",
    "\n",
    "print(output.shape)  # Should print: torch.Size([10, 8, 20, 64])\n",
    "print(attention_score.shape)  # Should print: torch.Size([10, 8, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b39ca42-0787-4287-89e1-de2df2b4c4b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1968, 0.1998, 0.1576, 0.1692, 0.1650, 0.2228],\n",
      "          [0.1798, 0.1859, 0.1614, 0.0000, 0.1887, 0.2079],\n",
      "          [0.1716, 0.1867, 0.1676, 0.2008, 0.1963, 0.0000],\n",
      "          [0.1787, 0.2006, 0.1427, 0.1793, 0.1731, 0.2368],\n",
      "          [0.1854, 0.2040, 0.1572, 0.1860, 0.2016, 0.1769],\n",
      "          [0.1720, 0.1963, 0.0000, 0.1823, 0.1769, 0.2008]],\n",
      "\n",
      "         [[0.1991, 0.1750, 0.1876, 0.0000, 0.2303, 0.1730],\n",
      "          [0.1958, 0.1988, 0.1624, 0.1635, 0.2220, 0.1686],\n",
      "          [0.0000, 0.1982, 0.1763, 0.0000, 0.2195, 0.1687],\n",
      "          [0.0000, 0.2095, 0.1748, 0.1474, 0.1863, 0.1750],\n",
      "          [0.2216, 0.1963, 0.1626, 0.1343, 0.2349, 0.1615],\n",
      "          [0.1771, 0.1786, 0.1691, 0.0000, 0.2365, 0.1819]],\n",
      "\n",
      "         [[0.1622, 0.2040, 0.1964, 0.0000, 0.1743, 0.2016],\n",
      "          [0.0000, 0.2116, 0.1659, 0.1522, 0.2108, 0.2241],\n",
      "          [0.1482, 0.2000, 0.1733, 0.1731, 0.1960, 0.2204],\n",
      "          [0.1593, 0.2224, 0.1824, 0.1546, 0.1952, 0.1973],\n",
      "          [0.1462, 0.2149, 0.1588, 0.1740, 0.1736, 0.2436],\n",
      "          [0.1592, 0.1906, 0.1775, 0.1531, 0.1977, 0.0000]],\n",
      "\n",
      "         [[0.1756, 0.1758, 0.1830, 0.1577, 0.2005, 0.0000],\n",
      "          [0.1726, 0.0000, 0.0000, 0.1653, 0.1888, 0.2223],\n",
      "          [0.1858, 0.1954, 0.1640, 0.1563, 0.1977, 0.2120],\n",
      "          [0.1743, 0.0000, 0.1787, 0.1710, 0.1933, 0.0000],\n",
      "          [0.0000, 0.0000, 0.1736, 0.1661, 0.2012, 0.2302],\n",
      "          [0.0000, 0.1902, 0.1711, 0.1502, 0.2111, 0.0000]],\n",
      "\n",
      "         [[0.1807, 0.1660, 0.0000, 0.2031, 0.1917, 0.0000],\n",
      "          [0.2006, 0.1950, 0.0000, 0.1834, 0.1806, 0.1927],\n",
      "          [0.1747, 0.2005, 0.1541, 0.2197, 0.1783, 0.0000],\n",
      "          [0.2001, 0.1654, 0.0000, 0.1924, 0.2148, 0.1641],\n",
      "          [0.1937, 0.1667, 0.1467, 0.2024, 0.2314, 0.1703],\n",
      "          [0.2151, 0.0000, 0.1494, 0.1927, 0.1832, 0.2077]],\n",
      "\n",
      "         [[0.1708, 0.2012, 0.0000, 0.1645, 0.1287, 0.1884],\n",
      "          [0.1982, 0.2246, 0.2138, 0.1475, 0.1372, 0.0000],\n",
      "          [0.1974, 0.2212, 0.2018, 0.1868, 0.1269, 0.1771],\n",
      "          [0.1759, 0.1890, 0.2256, 0.1825, 0.1286, 0.2095],\n",
      "          [0.2034, 0.2054, 0.2246, 0.1630, 0.0000, 0.1800],\n",
      "          [0.1841, 0.1998, 0.2529, 0.1506, 0.1394, 0.1843]],\n",
      "\n",
      "         [[0.2189, 0.1723, 0.0000, 0.1786, 0.1973, 0.1778],\n",
      "          [0.2061, 0.1595, 0.1716, 0.1672, 0.2111, 0.1957],\n",
      "          [0.1817, 0.1883, 0.1853, 0.1651, 0.2173, 0.1734],\n",
      "          [0.2093, 0.1483, 0.1597, 0.1777, 0.2221, 0.1940],\n",
      "          [0.2078, 0.1574, 0.1656, 0.1726, 0.2400, 0.1677],\n",
      "          [0.2258, 0.1436, 0.1863, 0.0000, 0.1979, 0.1764]],\n",
      "\n",
      "         [[0.1818, 0.2160, 0.1520, 0.2046, 0.1548, 0.2018],\n",
      "          [0.1698, 0.1920, 0.1607, 0.2103, 0.1517, 0.2267],\n",
      "          [0.0000, 0.2037, 0.1879, 0.1793, 0.1420, 0.2129],\n",
      "          [0.1789, 0.0000, 0.1441, 0.2072, 0.1581, 0.2107],\n",
      "          [0.2069, 0.2305, 0.0000, 0.1736, 0.1334, 0.2036],\n",
      "          [0.1736, 0.2347, 0.0000, 0.1831, 0.1480, 0.1803]]]])\n"
     ]
    }
   ],
   "source": [
    "print(attention_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110e64a-f163-432b-8b75-896013c568bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
